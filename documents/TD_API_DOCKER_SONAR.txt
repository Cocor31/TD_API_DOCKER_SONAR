##############################################################################
#	        TD API DOCKER SONAR
##############################################################################

Dans ce TD on créer une API avec Express puis des tests avec Jest
On utilise SonarQube pour vérifier la qualité du code
On créer un workflow dans gitHub pour faire du CI/CD. 
A chaque push sur la branche main => lancement des tests => Deploiement : Push sur DockerHub, envoi docker compose sur AWS EC2, puis lancement docker


voir vidéo BDD_SONAR_DOCKER.mkv

Mon projet github:
https://github.com/Cocor31/TD_API_DOCKER_SONAR.git

Code Florian:
https://github.com/Floriansp40/toulouse_mardi.git


#=====================================	
#	Création API
#=====================================
--------------------------		
	Récupérer code API
--------------------------
On récupère le code d l'api sur github
	git clone https://github.com/Floriansp40/toulouse_bd_23.git
	ou git clone https://github.com/Floriansp40/toulouse_bd_23.git .       <= le "." permet de ne pas ramener le dossier package
	ou degit https://github.com/Floriansp40/toulouse_bd_23.git             <= permet de ne pas ramener la config git du projet     <= installer degit avec : sudo npm i -g degit
	
renommer ".env.exemple" en ".env"

installer dépendences:
	npm i

#=====================================	
#	Création BDD de Dev
#=====================================
--------------------------		
	Création Manu BDD de Dev
--------------------------	
Création BDD pour projet:
	sudo service mariadb status
	=> Si stopped: sudo service mariadb start
	
	mysql -u admin -p (nimda)
	create database api_docker;
	GRANT ALL ON galera.* TO 'roger'@'%' IDENTIFIED BY 'regor';

ou	
--------------------------		
	Création BDD de Dev avec Docker
--------------------------
Création Base de donnée en Docker avec image mariadb
Sur dockerHub chercher mariadb pour voir comment configurer l'image

Créer à la racine de notre projet le fichier "docker-compose.yml"
mettre le contenu:
-------------------------------------------	  
version: '3.1'

services:
  db:
    image: mariadb:latest
    restart: always
    volumes:
      - ./mysql:/var/lib/mysql
    ports:
      - 3306:3306
    environment:
      MARIADB_ROOT_PASSWORD: toor
      MARIADB_DATABASE: api_docker
      MARIADB_USER: roger
      MARIADB_PASSWORD: regor

  adminer:
    image: adminer
    restart: always
    ports:
      - 8080:8080
-------------------------------------------	

Lancer le docker:
	docker compose up -d
	
Pour arreter le docker:
	docker compose down
	
	ou
	docker ps
	docker stop <id>
	
--------------------------	
  updater gitignore
--------------------------	
ajouter dans .gitignore le dossier défini pour la bdd lancer avec docker volumes:
	mysql
	
	
	
#=====================================	
#	Mise en place des Tests
#=====================================
--------------------------	
   Installation paquets
--------------------------
J'installe les paquet pour les tests:
	npm i -D jest supertest      <=  -D pour qu'ils se mettentent sous devDependance dans package.json

--------------------------	
Ajouter les scripts de test
--------------------------
Dans package.json dans variables scripts ajouter:
    "test": "jest --setupFiles dotenv/config --runInBand --testPathIgnorePatterns=init_bdd.test.js",                      <= runInBand: pour executer les tests les uns après les autres,  testPathIgnorePatterns: pour ignorer un fichier de test servant à fair la synchro des modeles dans la bdd
    "test:file": "func() { jest ${1}.test.js --setupFiles dotenv/config; }; func",                                        <= avec cette fonction on peut lancer le fichier "user_routes.test.js" avec "npm run test:file user"
    "test:cov": "jest --setupFiles dotenv/config --coverage --testPathIgnorePatterns=init_bdd.test.js"


--------------------------	
 Si test visuel updater gitignore
--------------------------	
ajouter dans .gitignore:
	coverage/

--------------------------	
Création tests
--------------------------	
créer dossier "test" à la racine du projet:
créer les fichiers tests:
- init_bdd.test.js       <= ce fichier sert à lancer la synchro des models dans la bdd durant les tests dans github action, il est ignoré pour le check des tests par jest
- main_route.test.js	 <= test des routes principales
- user_route.test.js	 <= test crud route user




#=====================================	
#	Génération Tests Auto et JSdoc par AI VsCode (CodiumAI)
#=====================================
--------------------------	
   Mettre Codium dans VScode
--------------------------
L'extension CodiumAI permet de générer des tests unitaire et commentaires ainsi que la JSdoc

Dans VScode installer extension "CodiumAI - Integrity Agent ..."

--------------------------	
   Générer JSdoc avec les commentaires dans Code
--------------------------
Installer généralement JSdoc:
	npm install -g jsdoc
	
Lancer génération JSdoc sur un seul fichier.js:
	jsdoc ./controller/User.js
	
	

#=====================================	
#	SONAR
#=====================================

--------------------------	
   Script Sonar Server  ("sonar-server.sh")
--------------------------
Il faut créer un serveur Sonar à partir d'une image docker, pour cela on va créer un script.
J'ai eu des bugs PC en lancant le script à la racine de mon Debian alors le mieux est de le laisser dans le projet sous "scripts"


A la racine du projet créer dossier "scripts"
Créer un fichier "sonar-server.sh"

mettre dedans:
--------------------------------------
mkdir -p ./opt/sonarqube/conf
mkdir -p ./opt/sonarqube/data
mkdir -p ./opt/sonarqube/logs
mkdir -p ./opt/sonarqube/extensions

export SONARQUBE_DIR=$(pwd)/opt

docker run --detach \
  -p 9000:9000  \
  -d \
  --name sonarqube  \
  --rm  \
  --stop-timeout 3600 \
  -v $SONARQUBE_DIR/conf:/opt/sonarqube/conf \
  -v $SONARQUBE_DIR/logs:/opt/sonarqube/data \
  -v $SONARQUBE_DIR/data:/opt/sonarqube/logs \
  -v $SONARQUBE_DIR/extensions:/opt/sonarqube/extensions \
sonarqube:8.7.1-community

# CTN_IP = $(docker inspect -f '{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}' sonarqube)

echo " "
echo "###############################"
echo "SONARQUBE Serveur is ready"
echo "His IP address in docker network is $(docker inspect -f '{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}' sonarqube)"
--------------------------------------


--------------------------		
	Lancer Sonar Server
--------------------------
aller dans le dossier du script:
	cd scripts    (depuis la racine de notre projet)
	
rendre le fichier executable puis l'éxécuter:	
	chmod u+x sonar-server.sh
	./sonar-server.sh

relever l'adresse IP donnée par le script
	ex : His IP address in docker network is 172.17.0.2

aller sur localhost:9000
	login: admin
	mot de pass: admin
	=> On vous demandera de changer le mot de passe

Create new project
	key: apitestsonar
	displayname: apitestsonar 
	=> set up
	token name : apitestsonar
	=> Generate
	
relever la clé token donnée qui servira pour le scan
	apitestsonar: 4cbcdd24c4157025698b2998564b104f4f317e9

--------------------------		
	Script Scan ("scan.sh")
--------------------------

Dans le dossier "script" à la racine du projet
créer dedans le fichier "scan.sh"
mettre dedans en remplaçant par les bonnes valeurs SONAR_HOST, SONAR_TOKEN, PROJECT_KEY :
--------------------------------------
export SONAR_HOST=172.17.0.2:9000
export SONAR_TOKEN=4cbcdd24c4157025698b2998564b104f4f317e9
export PROJECT_KEY=apitestsonar
export REPO=$(pwd)
export CONFIG_FILE=$(pwd)/sonar-project.properties

docker run \
    --rm \
    -e SONAR_HOST_URL="http://${SONAR_HOST}" \
    -e SONAR_SCANNER_OPTS="-Dsonar.projectKey=${PROJECT_KEY}" \
    -e SONAR_LOGIN="${SONAR_TOKEN}" \
    -v "${REPO}:/usr/src" \
    -v $CONFIG_FILE:/opt/sonar-scanner/conf/sonar-scanner.properties \
    sonarsource/sonar-scanner-cli
--------------------------------------

--------------------------		
	Fichier Paramètres Scan sonar ("sonar-project.properties")
--------------------------

Créer ls fichier "sonar-project.properties" à la racine du projet
mettre dedans en remplaçant par les bonnes valeurs projectKey, projectName, sources (qui est le dossier de notre projet à scanner) :
-----------------
# Metadata
sonar.projectKey=apitestsonar
sonar.projectName=apitestsonar

sonar.projectVersion=1.0.0
sonar.projectEncoding=UTF-8

# Source
sonar.sources=api

# Exclude
sonar.exclusions=node_modules/*,api/coverage/lcov-report/*,test/*,mysql/*,api/scripts/*
--------------------------------------

--------------------------		
	Lancer Scan sonar
--------------------------

deplacer le script "scan.sh" dans le projet à côté du fichier "sonar-project.properties"  
( on est donc positionner à la racine du projet)

rendre le fichier executable puis l'éxécuter:
	chmod u+x scan.sh
	./scan.sh
	
	=> On peut voir les résultats sur http://localhost:9000/

--------------------------		
	Correction CORS policies
--------------------------	
mettre localhost sur origin use :
app.use(cors({ origin :"localhost"

--------------------------		
	Correction exposition du nom Express
--------------------------	
npm i helmet

app.use(helmet.hidePoweredBy .... ???????  <= A corriger

--------------------------		
	Expliquer à Sonar où sont les tests
--------------------------	
... voir vidéo BDD_SONAR_DOCKER.mkv à partir de 1:20:00

dans fichier "sonar-project.properties" ajouter sous #source:
	sonar.tests=test     <= "test" représente le dossier de test dans notre projet
	
puis ajouter:
	# coverage reporting
	sonar.javascript.lcov.reportPaths=coverage/lcov.info     <=  "coverage/lcov.info" est l'endroit où vont les résultats de notre test taux de couverture lancer avec jest

on peut relancer un scan avec la commande :
	il faut aun préalable avoir lancer le test jest avec le taux de couverture (script npm run test:cov)
	./scan.sh
		
dans browser sur http://localhost:9000/
on doit voir le taux de couverture qui remonte

--------------------------	
 Updater .gitignore
--------------------------	
ajouter dans .gitignore:
	scripts/opt              <=  Dans le cas où on ait lancer le serveur depuis notre projet
	.scannerwork


#=====================================	
#	Creation Docker de l'API
#=====================================
--------------------------		
	Config Dockerfile
--------------------------
Créer fichier "Dockerfile" à la racine du projet

mettre dedans le contenu:
-------------------------
FROM node:18-alpine

ADD . /app
WORKDIR /app

RUN npm i --omit=dev          => --omit=dev : sert à ne pas installer les dépendances dev

EXPOSE 23000
CMD npm run start
-------------------------

--------------------------		
	Créer dockeringnore
--------------------------
.dockerignore

ajouter :
	node_modules
	mysql           <=   dossier local de la base de données qui sera créer au lancement de notre docker
	coverage
	scripts
	documents
	.scannerwork
	test
	scan.sh
	sonar-project.properties
	docker-compose.yml
	Dockerfile
	
--------------------------		
	Build docker de l'api
--------------------------
lancer commande à la racine du projet où se trouve le fichier Dockerfile
	docker build -t api_docker_sonar .

lister les image docker
	docker image list
=> il y a bien l'image api_docker_sonar créer


#=====================================	
#	Creation Docker Compose du projet  API + BDD + Adminer
#=====================================

créer fichier "docker-compose.yml" à la racine du projet

mettre le contenu:
-----------------------------------------------------
version: '3.1'

services:

  bdd:
    container_name: bdd
    image: mariadb:latest
    restart: always
    volumes:
      - ./mysql:/var/lib/mysql
    ports:
      - 3306:3306
    environment:
      MARIADB_ROOT_PASSWORD: toor
      MARIADB_DATABASE: api_docker
      MARIADB_USER: roger
      MARIADB_PASSWORD: regor

  api:
    container_name: api
    image: cocor31/api_docker:main
    restart: always
    ports:
      - 23000:23000
    environment:
      DB_HOST: bdd
      DB_NAME: api_docker
      DB_USER: roger
      DB_PASS: regor
      SERVER_PORT: 23000
    depends_on:
      bdd:
        condition: service_started

  adminer:
    container_name: adminer
    image: adminer
    restart: always
    ports:
      - 8080:8080
------------------------------------------------------

l'image "api_docker_sonar" existe sur mon poste car je viens de la créer avec le Build, du coup Docker n'ira pas la chercher sur DockerHub


--------------------------		
	Lancer docker compose
--------------------------
lancer image docker
	docker compose up -d

--------------------------		
	Vérifier que l'api fonctionne
--------------------------
aller sur l'url définie pour l'api:
	http://localhost:23000/

tester un GET:
	http://localhost:23000/users

tester PUT avec postman sur
	http://localhost:23000/users
	

--------------------------		
	Eteindre le Processus docker compose
--------------------------
	docker compose down
	
--------------------------		
	supprimer image docker
--------------------------

docker rmi nom_image --force



#=====================================	
#	CI
#=====================================
créer dossier ".github" puis "workflows" dedans:
créer fichier ci.yml
mettre le contenu:
-----------------------------------------------------
name: Integration continue

on:
    push:
        branches: ["main"]
    pull_request:
        branches: ["main"]

jobs:
    routage:
        if: ${{ !contains(github.event.head_commit.message, '#code')}}
        runs-on: ubuntu-latest

        services:
            mariadb:
                image: mariadb:latest
                env:
                    MARIADB_ROOT_PASSWORD: toor
                    MARIADB_DATABASE: test
                    MARIADB_USER: test
                    MARIADB_PASSWORD: test
                ports:
                    - 3306:3306
                options: --health-cmd="healthcheck.sh --connect --innodb_initialized" --health-interval=10s --health-timeout=5s --health-retries=3

        env:
            DB_HOST: 127.0.0.1
            DB_NAME: test
            DB_USER: test
            DB_PASS: test

        steps:
            - name: Checkout
              uses: actions/checkout@v3

            - name: Check database connection
              run: |
                sudo apt-get install -y mysql-client
                mysql --host 127.0.0.1 --port 3306 -u root -ptoor -e "SHOW DATABASES"

            - name: Setup node
              uses: actions/setup-node@v3
              with:
                node-version: 18.x
            - name: Install Dependencies
              run: npm i

            - name: Init database
              run: npm run test:file init_bdd

            - name: Run Main Test
              run: npm run test:file main_route   

            - name: Run User test
              run : npm run test:file user_route
    
    deploy:
        needs: [routage]
        if: ${{ github.event_name == 'push' && github.ref_name == 'main'}}        
        uses: ./.github/workflows/cd_docker.yml
        secrets: inherit
-----------------------------------------------------

#=====================================	
#	CD
#=====================================
lien exemple deploiement AWS EC2:
https://lightrains.com/blogs/deploy-aws-ec2-using-github-actions/

créer fichier "cd_docker.yml" dans le dossier ".github/workflows" 

mettre le contenu (attention à mettre le bon nom à "images":
-----------------------------------------------------
name: Deploiement continu sur Server

on:
    workflow_call

jobs:
    pushDockerHub:      
      runs-on: ubuntu-latest

      steps:
        - name: Checkout
          uses: actions/checkout@v3
        - name: Docker login
          uses: docker/login-action@f4ef78c080cd8ba55a85445d5b36e214a81df20a
          with:
            username: ${{ secrets.DOCKERHUB_LOGIN }}
            password: ${{ secrets.DOCKERHUB_TOKEN }}

        - name: Extract Metada
          id: meta
          uses: docker/metadata-action@98669ae865ea3cffbcbaa878cf57c20bbf1c6c38
          with:
            images: cocor31/api_docker

        - name: Build and Push
          uses: docker/build-push-action@v4
          with:
            context: .
            file: ./Dockerfile
            push: true
            tags: ${{ steps.meta.outputs.tags }}
            labels: ${{ steps.meta.outputs.label }}
    sendComposeOnServer:
        needs: [pushDockerHub]
        runs-on: ubuntu-latest
    
        steps:
          - name: Checkout code
            uses: actions/checkout@v3
          # - name: Configure SSH
          #   uses: webfactory/ssh-agent@v0.5.1
          #   with:
          #     ssh-private-key: ${{ secrets.SSH_KEY }}
          - name: copy via ssh key
            uses: appleboy/scp-action@v0.1.4
            with:
              host: ${{ secrets.HOST }}
              username: ${{ secrets.USERNAME }}
              port: ${{ secrets.PORT }}
              key: ${{ secrets.SSH_KEY }}
              source: ${{ secrets.SOURCE_DIR }}
              target: ${{ secrets.TARGET_DIR }}  

    pullServer:
      needs: [pushDockerHub,sendComposeOnServer]
      runs-on: ubuntu-latest
      
      steps:
        - name: Checkout
          uses: actions/checkout@v3      
        - name: Server update
          uses: appleboy/ssh-action@master
          with:
            host: ${{ secrets.HOST }}
            username: ${{ secrets.USERNAME }}
            port: ${{ secrets.PORT }}
            key: ${{ secrets.SSH_KEY }}

            script: |
              docker pull cocor31/api_docker:main
              docker-compose up -d
-----------------------------------------------------


--------------------------		
	Créer token de connexion dans DockerHub
--------------------------
Dans DockerHub aller dans My Account/Security => New Access Token
Token Description: GitHub_Workflows

Copier le token:
	user : cocor31
	token ex: dckr_pat_9ppqAIz25swxGReBGo9HbwUM


--------------------------		
	Setter les variable secrete dans GitHub
--------------------------
Dans GitHub aller dans Setteing/Secrets and variables/Actions => New Repository secret
Ajouter les deux variables Docker
	DOCKERHUB_LOGIN
	DOCKERHUB_TOKEN

Ajouter les variables Server (ici instance AWS EC2)
	HOST = adresse public server
	USERNAME = user avec les droits sur le serveur pour connexion ssh (ex:admin)
	PORT= port ssh de connexion à notre server (ex: 22)
	SSH_KEY = .pem sur PC
	SOURCE_DIR = ex: "api/*" ou "./docker-compose.yml,frontend/*,nginx/*"
	TARGET_DIR = ex: "."


#=====================================	
#	Test du Docker Envoyé sur DockerHub par GitHub
#=====================================

créer nouveau dossier sur debian:
y mettre un fichier "docker-compose.yml" avec ce contenu:
----------------------------------------
version: '3.1'

services:

  bdd:
    image: mariadb:latest
    restart: always
    volumes:
      - ./mysql:/var/lib/mysql
    ports:
      - 3306:3306
    environment:
      MARIADB_ROOT_PASSWORD: toor
      MARIADB_DATABASE: api_docker
      MARIADB_USER: roger
      MARIADB_PASSWORD: regor

  api:
    image: cocor31/api_docker:main
    restart: always
    ports:
      - 23000:23000
    environment:
      DB_HOST: bdd
      DB_NAME: api_docker
      DB_USER: roger
      DB_PASS: regor
      SERVER_PORT: 23000

  adminer:
    image: adminer
    restart: always
    ports:
      - 8080:8080
----------------------------------------

recupérer l'image du projet sur DockerHub
	docker pull cocor31/api_docker:main

lancer docker compose depuis le dossier local:
	docker compose up -d

--------------------------		
	Aller sur Adminer
--------------------------
http://localhost:8080/

entrer les élements de connexion mis dans le "docker-compose.yml"
      Server: bdd
	  Utilisateur: roger
	  Mot de passe: regor
      Base de donnée: api_docker





#=====================================	
#	Deploiement sur AWS EC2
#=====================================

console EC2:
https://eu-west-3.console.aws.amazon.com/ec2/home?region=eu-west-3#Home:

--------------------------		
	Création instance EC2
--------------------------
créer une instance EC2 avec Debian

Ouvrir les ports dans le groupe de sécurité de notre instance:
TCP 					22 			par	défaut ssh
TCP personnalisé		23000       port de notre API
HTTP					80          pour connexion internet
TCP						8080        si on veut avoir accès à adminer


--------------------------		
	Installation Docker
--------------------------
connexion sur powershell
ssh -i ".\.ssh\amazon_ssh.pem" admin@IP_public_server

installer docker:
créer fichier install_docker.sh avec le contenu suivant:
---------------------------------------------------
#!/bin/bash

echo "########################################################"
echo "###                                                  ###"
echo "### This script install Docker CE and Docker-Compose ###"
echo "###                                                  ###"
echo "### Warning : Due to the newgrp command, this script ###"
echo "### auto relog you for the first installation (only).###"
echo "###                                                  ###"
echo "########################################################"


echo "Let's go ?"
read -r answer

echo " "
echo "Install Dependency packages"
sudo apt -y install apt-transport-https ca-certificates curl gnupg2 software-properties-common

echo "Add Docker's Official GPG Key"
curl -fsSL https://download.docker.com/linux/debian/gpg | sudo gpg --dearmor -o /etc/apt/trusted.gpg.d/docker-archive-keyring.gpg

echo "Add Docker repository"
sudo add-apt-repository \
   "deb [arch=amd64] https://download.docker.com/linux/debian \
   $(lsb_release -cs) \
   stable"

echo "Update source list"
sudo apt update

echo "Install Docker CE and CLI"
sudo apt install docker-ce docker-ce-cli containerd.io -y

echo "Add his user account to docker group"
sudo usermod -aG docker $USER
newgrp docker << END

echo "Download last compose"
curl -s https://api.github.com/repos/docker/compose/releases/latest | grep browser_download_url  | grep docker-compose-linux-x86_64 | cut -d '"' -f 4 | wget -qi -

echo "Make binary executable"
chmod +x docker-compose-linux-x86_64

echo "Move compose to the PATH"
sudo mv docker-compose-linux-x86_64 /usr/local/bin/docker-compose

END

sudo su $USER

echo "############################"
echo " "
docker version
docker-compose version

exit 0
---------------------------------------------------------------------


	
Rendre le fichier executable puis l'éxécuter:	
	chmod u+x install_docker.sh
	./install_docker.sh



--------------------------		
	Installation LazyDocker
--------------------------

entrer toutes ces commandes à la suite sur terminal ssh:

LAZYDOCKER_VERSION=$(curl -s "https://api.github.com/repos/jesseduffield/lazydocker/releases/latest" | grep -Po '"tag_name": "v\K[0-9.]+')
curl -Lo lazydocker.tar.gz "https://github.com/jesseduffield/lazydocker/releases/latest/download/lazydocker_${LAZYDOCKER_VERSION}_Linux_x86_64.tar.gz"
mkdir lazydocker-temp
tar xf lazydocker.tar.gz -C lazydocker-temp
sudo mv lazydocker-temp/lazydocker /usr/local/bin
lazydocker --version
rm -rf lazydocker.tar.gz lazydocker-temp


pour lancer lazydocker entrer commande:
	lazydocker





#=====================================	
#	Vérif Fonctionnement API sur AWS EC2
#=====================================
Il peut y avoir un problème lors de l'éxécution workflow lors de la copie des fichiers sur server. Ceci peut etre un problème de droit sur les dossiers et fichiers 
déja créés sur le serveur avec pour propriétaire "root" et non "admin". Pour que gitHub puisse exécuter la copie, il faudra soit changer le propriétaire root -> admin, 
soit supprimer les fichiers ou dossiers pour les laisser se recréer avec le user admin par github action.

Aller sur l'adresse
	http://adresse_server:23000/
	=> On devrait voir : I'm online All it's ok 
	http://adresse_server:23000/users
	=> On devrait voir notre liste de users
	
Adminer:
	http://adresse_server:8080/  => si on a ouvert le port
		

Un dossier mysql (volume docker) doit se créer sur notre instance


#=====================================	
#	Mise en place Reverse Proxy Nginx
#=====================================
créer un dossier "nginx" avec un fichier "nginx.conf" à l'intérieur (le faire sur serveur directement ou dans le projet avec une copie sur serveur cible dans le workflow)
Dans le fichier "nginx.conf" mettre le contenu suivant:
---------------------------------------------------------------------
server{
        listen 80;
        server_name  localhost;

        location / {
                root /var/www/front-end;
                }

        location /adminer {
                proxy_pass http://adminer:8080;
                proxy_http_version 1.1;
                proxy_set_header Upgrade $http_upgrade;
                proxy_set_header Connection 'upgrade';
                proxy_set_header Host $host;
                proxy_cache_bypass $http_upgrade;
                }

        location /api {
                proxy_pass http://api:23000;
                proxy_http_version 1.1;
                proxy_set_header Upgrade $http_upgrade;
                proxy_set_header Connection 'upgrade';
                proxy_set_header Host $host;
                proxy_cache_bypass $http_upgrade;
                }
}					
---------------------------------------------------------------------


Il faut mettre aussi les ports 23000 (api) et 8080 (adminer) en "expose" dans le docker file pour qu'ils ne soient pas accessibles de l'exterieur du docker


#=====================================	
#	Ajout de Prefix pour le chemin de l'Api
#===================================== 
On modifie le routage dans app.js pour prendre en compte une variable d'environnement PREFIX qui pourra être initialiséé à "/api" dans le Docker compose
et aussi dans le fichier "nginx.conf" pour la location "/api" qui pointera vers http://api:23000





#=====================================	
#	FrontEnd
#===================================== 
Ajout d'un front-end qui interagit avec l'API

doc get host current url path
https://css-tricks.com/snippets/javascript/get-url-and-url-parts-in-javascript/



Ne pas oublier de mettre à jour le workflow "cd_docker.yml" pour effectuer la copie du front-end
dans le step "sendFilesToServer" modifier
	source: "./docker-compose.yml,frontend/*,nginx/*"
	
ou bien, Changer variable SOURCE_DIR dans GitHub action pour copier le dossier frontend
SOURCE_DIR = "./docker-compose.yml,frontend/*,nginx/*"

Mettre à jour le docker compose pour ajouter le Nginx (reverse proxy + frontend)
---------------------------------------------------------------------
version: '3.1'

services:

  bdd:
    container_name: bdd
    image: mariadb:latest
    restart: always
    volumes:
      - ./mysql:/var/lib/mysql
    ports:
      - 3306:3306
    environment:
      MARIADB_ROOT_PASSWORD: toor
      MARIADB_DATABASE: api_docker
      MARIADB_USER: roger
      MARIADB_PASSWORD: regor

  api:
    container_name: api
    image: cocor31/api_docker:main
    restart: always
    ports:
      - 23000:23000
    environment:
      DB_HOST: bdd
      DB_NAME: api_docker
      DB_USER: roger
      DB_PASS: regor
      SERVER_PORT: 23000
      PREFIX: /api
    depends_on:
      bdd:
        condition: service_started

  adminer:
    container_name: adminer
    image: adminer
    restart: always
    expose:
      - "8080"
  nginx:
    image: nginx
    volumes:
      - ./nginx:/etc/nginx/conf.d
      - ./frontend:/var/www/front-end
    ports:
      - "80:80"
---------------------------------------------------------------------





#=====================================	
#	Récap .dockerignore
#=====================================
Ajouter dans .dockerignore:
node_modules
mysql
coverage
scripts
nginx
documents
.scannerwork
test
scan.sh
sonar-project.properties
docker-compose.yml
Dockerfile

#=====================================	
#	Récap .gitignore
#=====================================
Ajouter dans .gitignore:
node_modules
.env
mysql
.scannerwork
scripts/opt
coverage/

#=====================================	
#	Dépot florian correction TD
#=====================================

récupérer dépot git: https://github.com/Floriansp40/toulouse_mardi.git

degit https://github.com/Floriansp40/toulouse_mardi.git

#=====================================	
#		ViteJs
#=====================================
Vite JS permet de créer rapidement une application React
il suffit de seplacer dans un dossier depuis terminal debian et entrer la commande:
	npm create vite@latest
	=> puis donner le nom de l'application
	=> react
	=> variant: javascript

#=====================================	
#	Deploiement FrontEnd sur Versel (créer site internet)
#=====================================
Il est possible d'utiliser https://vercel.com/ pour builder et deployer directement un projet gitHub (React par exemple)
Le site internet à un nom de domaine propre à versel. Il est possible d'acheter un nom de domaine sur versel.
C'est utile pour de petit projet.
Pour des grands projets, mieux vaut les mettre sur serveur.

On peut aussi utiliser netify.com pour deployer son site depuis un dépot gitHub
guide netify:
https://www.netlify.com/blog/2016/09/29/a-step-by-step-guide-deploying-on-netlify/


#=====================================	
#	Acceder aux fichiers WSL depuis Windows
#=====================================
Dans explorateur Windows
	\\wsl$\Debian

Connetion server en ssh depuis powershell
	ssh -i ".\.ssh\amazon_ssh.pem" admin@IP_public_server




#=====================================	
#	BackUp BDD externalisée
#=====================================
voir vidéo Florian du 20/11/23
voir cours Classroom : https://classroom.google.com/w/NjM2Mjk4NTY3MDc1/t/all

Faire un simple dump dans Debian:
	mysqldump -u admin -p roger > mysql_backup.sql

Voir script Florian

--------------------------		
	Connexion Gdrive
--------------------------
faire procedure de connexion au drive avec mon serveur (Debian)
installer gdrive sur mon Debian
doc: https://github.com/glotlabs/gdrive

création api credentials:
https://github.com/glotlabs/gdrive/blob/main/docs/create_google_api_credentials.md

--------------------------		
	Script BackUp BDD
--------------------------
créer script qui dump la bdd puis compresse puis envoie sur google drive avec commande gdrive
	un script est en .sh  ex: mysql_backup.sh

exemple script florian à mettre sur serveur où est la bdd:
-------------------------------------------------
#!/bin/bash
#*********************************************************************
# Fichier de sauvegarde de la base de donnees - Exemple
#
# Version : 1.0
# Date    : 20-11-2023
#
# ********************************************************************

# Variable de la base de donnees
dbHost="127.0.0.1"
dbPort="3306"
dbName="world"
dbUser="admin"
dbPawd="nimda"

# Dossier pour la sauvegarde
dbBackup="/home/florian/mysql"


# ********************************************************************
# Debut de la sauvegarde

# Recuperation de la date
DATE=`date +%Y-%m-%d`
/bin/touch ${dbBackup}/mysql_galera_${DATE}.sql.gz

# Sauvegarde de la base
mysqldump -h $dbHost -u $dbUser -p$dbPawd --port $dbPort --opt $dbName | gzip -9 > ${dbBackup}/mysql_galera_${DATE}.sql.gz

# Nettoyage des vieux fichiers de sauvegarde
find ${dbBackup}/mysql_galera_*.sql.gz -type f -mtime +4 -delete

# Export sur le google drive
/home/florian/gdrive files upload ${dbBackup}/mysql_galera_${DATE}.sql.gz

# Fin
exit 0
------------------------------------------------- 


--------------------------		
	Tache planifiée avec Crontab
--------------------------
crontab doc:
https://linuxtricks.fr/wiki/cron-et-crontab-le-planificateur-de-taches

cron schedule expressions:
https://crontab.guru/#5,10_4_20_12_7

voir pdf pour expression crontab:


On peut ensuite lancer un routine avec crontab:
	créer fichier log
	log touch log_galera_backup.log
Entrer dans crontab sur terminal debian: https://classroom.google.com/w/NjM2Mjk4NTY3MDc1/t/all
		crontab -e
Dans crontab ecrire:
25 **** /home/florian/mysql_backup.sh > /home/florian/log_galera_backup.log


taches automatisées:  crontab sur linux




!!!!!!!!!!!!!!!!!!!!!!!!!!!
Manque expliquer à Sonar où sont les tests  Voir vidéo de Florian sur youtube ou BDD_TD_SONAR-partie1.mkv et BDD_TD_SONAR-partie2.mkv
Sauvegarde BDD sur drive



#=====================================	
#	!!!!!!!!!!!!! Penser à ajouter les documents dans GitHub
#=====================================
enlever "documents" de .gitignore
mettre les fichiers .txt

